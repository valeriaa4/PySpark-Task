{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBZ1TzUAvWVY8IXm01mmHm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark boto3\n",
        "! pip install -q awscli\n",
        "! aws configure"
      ],
      "metadata": {
        "id": "2Szyzs3ypM7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b8MmQli7VOE"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import boto3\n",
        "from boto3.dynamodb.conditions import Key\n",
        "import json\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PySpark\").getOrCreate()\n",
        "\n",
        "file_path = \"/content/dados_importar.csv\"\n",
        "\n",
        "df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(\"Tipo da Tarefa ID\").drop(\"Data de Conclusão\").drop(\"Status\").drop(\"Usuário\")"
      ],
      "metadata": {
        "id": "jBs4sneFAov8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('Nome da Tarefa', 'name').withColumnRenamed('Tipo da Tarefa', 'type_task').withColumnRenamed('Data de Criação', 'date').withColumnRenamed('Status Descrição', 'status').withColumnRenamed('ID do Usuário', 'PK')"
      ],
      "metadata": {
        "id": "CDQOc9LQ-fVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(col(\"status\") != \"Cancelado\").filter(col(\"Usuário\") != \"Pedro da Silva\")"
      ],
      "metadata": {
        "id": "2wmZX0ps_SRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('status', regexp_replace('status', 'Concluído', 'done')).withColumn('status', regexp_replace('status', 'A Fazer', 'todo'))\n",
        "df = df.withColumn(\"date\", to_date(\"date\"))"
      ],
      "metadata": {
        "id": "lLBWa_-k78UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gerar item_id para SK com função nativa do pyspark\n",
        "df = df.withColumn(\"item_id\", sha2(concat_ws(\"-\", \"date\", \"name\", \"status\"), 224))"
      ],
      "metadata": {
        "id": "WOrFYl9ZIzT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# estruturando PK e SK, trocando user_id\n",
        "df = df.withColumn(\"PK\", concat_ws(\"\", lit(\"USER#\"), lit(\"b4c894d8-3091-70b2-79f6-78ebfd1b527f\")))\n",
        "df = df.withColumn(\"SK\", concat_ws(\"\", lit(\"LIST#\"), df[\"date\"], lit(\"ITEM#\"), df[\"item_id\"]))\n",
        "df.show(truncate=False)\n",
        "print(df.count())"
      ],
      "metadata": {
        "id": "GK7iUmBKvDRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_json = df.toJSON().collect()"
      ],
      "metadata": {
        "id": "7Z1NnE7OJgnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "dynamodb = boto3.resource('dynamodb')\n",
        "table = dynamodb.Table('MARKET_LIST')\n",
        "\n",
        "with table.batch_writer() as batch:\n",
        "  for i, row in enumerate(data_json):\n",
        "    item = json.loads(row)\n",
        "    try:\n",
        "      batch.put_item(Item=item)\n",
        "      if i % 100 == 0:\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "      print(\"Erro ao inserir item:\", item)\n",
        "      print(\"→\", e)\n",
        "print(f\"Sucesso! {len(data_json)} itens processados.\")"
      ],
      "metadata": {
        "id": "iSHJprdCXrOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}